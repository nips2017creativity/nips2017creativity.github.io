In the last year, generative machine learning and machine creativity have gotten a lot of attention in the non-research world. At the same time there have been significant advances in generative models for media creation and for design. This one-day workshop explores several issues in the domain of generative models for creativity and design. We will look at algorithms for generation and creation of new media and new designs, engaging researchers building the next generation of generative models (GANs, RL, etc) and also from a more information-theoretic view of creativity (compression, entropy, etc). We will investigate the social and cultural impact of these new models, engaging researchers from HCI/UX communities. We’ll also hear from some of the artists and musicians who are adopting machine learning approaches like deep learning and reinforcement learning as part of their artistic process.  We’ll leave ample time for discussing both the important technical challenges of generative models for creativity and design, as well as the philosophical and cultural issues that surround this area of research.

The goal of this workshop is to bring together researchers and creative practitioners interested in advancing art and music generation to present new work, foster collaborations and build networks. Workshops participants will include the organisers, a number of invited speakers (see below), authors of accepted papers, and creators of accepted artworks.

<center>
<img src="https://cdn.rawgit.com/nips2017creativity/nips2017creativity.github.io/c947e344/assets/nips_logo.svg" width="90%"/>
</center>

## Keynote Speakers

[Jürgen Schmidhuber](http://people.idsia.ch/~juergen/), Director & Professor at The Swiss AI Lab IDSIA

[Ian Goodfellow](https://research.google.com/pubs/105214.html), Staff Research Scientist, Google Brain

[Rebecca Fiebrink](https://www.doc.gold.ac.uk/~mas01rf/homepage/), Senior Lecturer, Goldsmiths University of London

[Ahmed Elgammal](https://www.cs.rutgers.edu/~elgammal/Home.html), Director of the Art & Artificial Intelligence Lab, Rutgers University

[Emily Denton](http://www.cs.nyu.edu/~denton/), PhD student, Courant Institute at New York University

## Important Dates

RIGHT NOW: Register for NIPS workshop attendance [here](https://nips.cc/Register2) if you think you will submit something. NIPS will sell out shortly, and you can receive a refund if you end up not coming and you cancel before Nov. 16, 2017, 4:59 p.m. Pacific Time. You do not need to register for the full conference in order to register for the workshops. More information on [NIPS website] (https://nips.cc/Conferences/2017/Pricing)

3 November 2017: Submission date for papers and art

10 November 2017: Acceptance notification for papers and art submissions

28 November 2017:  Deadline for final copy of accepted papers

4–9 December 2017: NIPS Conference

8 December 2017: Workshop

## How to Participate

We invite participation in the form of papers and/or artwork.

### To Submit a Paper

We invite participants to submit 2-page papers in the NIPS format, to be submitted to: `nips2017creativity@gmail.com`

In the subject line of your email, please put:

`NIPS Workshop: [Paper title]`

Topics may include (but are not limited to):
- Presentation of new machine learning techniques for generating art, music, or other creative outputs using, for instance, reinforcement learning, generative adversarial networks, novelty search and evaluation, etc
- Quantitative or qualitative evaluation of machine learning techniques for creative work and design 
- Tools or techniques to improve usability or usefulness of machine learning for creative practitioners
- Descriptions, reflections, or case studies on the use of machine learning in the creation of a new art or design work
- Information-theoretic views of creativity
- Aesthetic, philosophical, social, and cultural considerations surrounding the use of machine learning in creative practice

On the submission page, you may also indicate whether you would like to present a demo of your work during the workshop (if applicable).

Papers will be reviewed by committee members, and accepted authors will present at the workshop in the form of a short talk, panel, and/or demo. At least one author of each accepted paper must register for and attend the workshop. Accepted papers will appear on the workshop website.

### To Submit Artwork

We welcome submission of artwork that has been created using machine learning (autonomously or with humans). We invite art in any medium, including but not limited to sound and music, image, video, dance, text, physical objects, food, etc… We will be able to accommodate work submitted in one of the following formats:
- Video 
- Audio (maximum 2 channel)
- Still image
- Website
- Other types of submissions (e.g., physical artefacts, performances, text, …) should be documented using one or more of the above formats. For instance, you might submit a video of a machine-learning-generated dance piece or a website documenting a text generation piece.

On this submission [page](https://docs.google.com/forms/d/e/1FAIpQLSdN3TzfqreAgKWvV3pvps1eSJ0izCIrWvqMogQfXdydHkm4EA/viewform?c=0&w=1&usp=mail_form_link), you will also be asked for a short text description of your work and a description of how machine learning was used in its creation.

Art submissions will be reviewed by committee members.





We will host an online gallery of accepted art submissions on the workshop website. While we will do our best to show a number of art pieces at the workshop itself, we will most likely not have access to adequate equipment and space to support a substantial exhibit. We may invite creators of accepted artwork to participate in the form of a short talk, panel, and/or demo.

Artists submitting work are encouraged though not required to attend in person. 

## Contact

If you have any questions, please contact us at `nips2017creativity@gmail.com`

Workshop website: [https://nips2017creativity.github.io](https://nips2017creativity.github.io)

## Schedule

TBD

## Organisers

[Douglas Eck](https://twitter.com/douglas_eck), Google Brain

[David Ha](https://twitter.com/hardmaru), Google Brain

[S. M. Ali Eslami](https://twitter.com/arkitus), DeepMind

[Sander Dieleman](https://twitter.com/sedielem), DeepMind

[Rebecca Fiebrink](https://twitter.com/RebeccaFiebrink), Goldsmiths University of London

[Luba Elliott](https://twitter.com/elluba), AI Curator
